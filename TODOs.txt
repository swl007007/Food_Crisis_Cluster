known situation:
1. test and train data misalignment, alot of missing area
2. majority voting system still implement 4/9 threshold
3. accuracy in train and test seems different due to unkown issue

INVESTIGATION:
WARNING : 1.the heterogeneity of polygon gscore (most gscore(77%) is 0, with only 4% positive and 18.52% negative)


Action Points:
TODO(CRITICAL):
0.assemble a different dataset from FEWSNET_zscore
1. add growing windows from MODIS（area admin code, year, month, last season start, last season end, last_season_start_2, last_season_end_2, in-season?, current_season_start）
2. append EVI, rainfall, temperature, GPP to growing windows df
3.for data after 2012, for 4,8,12 months prediction scope, find respective "contemporary month", then according to the contemporary month find growing window variable
4. create growing window mask for each month
5. make sum, min, max, of GPP, temperature, rainfall, EVI for growing window periods, if the "current month" is in-season, find the mean of GPP, temperature, rainfall, EVI for in-season period


Concurrent






KNOWN ISSUES:
1.solve accuracy map axis name issue
2.think about the architecture of two layer model
3. xgboost name issue(the output name is not correct)
4.use ChatGPT to parse pre-2017 locations to country ISO and admin1 codes
5.skip baseline module in production mode



IMPORTANT NOTE
for one round:
parent RF -> using the parent RF validation/train to calculate groupwise metrics -> partition (LTSS/q) -> 
partition contiguity refinement -> child model using child model specific validation/train -> child model performance metrics -> partition significance test ->
 in RF, can also copy parent RF weights to one of the child RF

